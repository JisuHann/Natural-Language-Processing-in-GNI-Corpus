{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFh-iaN1KHxJ",
        "colab_type": "text"
      },
      "source": [
        "## Natural Language Understanding with Sequence to Sequence Models\n",
        "Seq2Seq 모델을 이용하여 문장의 intent의도 학습해보기\n",
        "\n",
        "이 코드를 통해 ATIS 데이터셋, Keras 라이브러리를 이용해 Slot Filling을 보이고자 한다. (인간의 질문에 내포되어있는 의도를 파악하는 방법을 학습하고자 한다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-uNAjITeojJ",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7414ca6c-0a1f-49ba-a484-4ba0bea363ee"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d19ce894-9ea0-4156-92f8-02735c9a5f9b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d19ce894-9ea0-4156-92f8-02735c9a5f9b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving atis.test.pkl to atis.test.pkl\n",
            "Saving atis.train.pkl to atis.train.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw9IHhBwLRky",
        "colab_type": "text"
      },
      "source": [
        "## 인간의 의도 Decode해독하기  \n",
        "이 섹션에서는 Natural Language Understanding(문장안의 숨은 의도 확인하기)를 위한 Seq2Seq 모델을 구현합니다.  \n",
        "일반적으로 이 작업에는 문장 내의 의도 감지(Intent Detection)와 슬롯 채우기 (Slot Filling)라는 두 가지 작업이 포함됩니다.  \n",
        "전자는 사용자 발화를 의도로 분류하려고 시도합니다. 후자는 이 의도의“Argument(정보)”를 찾아내려고한다.  \n",
        "  \n",
        "\n",
        "\n",
        "### 데이터 세트 탐색하기\n",
        "이 모델은 잘 알려진 ATIS Dataset(항공 여행 정보 시스템)을 바탕으로 합니다.  \n",
        "이 데이터셋은 Pickle 형식의 전처리된 데이터 셋 버전으로 이루어져 있습니다.\n",
        "이 데이터셋에는 여행자들이 제출한 Query들을 포함해,  \n",
        "사용자의 의도는 말로 라벨화되어 slot filling에 사용됩니다. \n",
        "\n",
        "다음의 데이터는 사전 및 텐서의 열차 데이터들을 변수로 저장합니다. 이와 더불어 쿼리, 단어 벡터, 의도, 슬롯 및 슬롯 벡터의 몇 가지 예를 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL1kFP6aBDCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d6d5ffec-16fb-42b2-e08c-a7cde732edd5"
      },
      "source": [
        "for file in uploaded.keys():\n",
        "  print('Uploaded file \"{name}\" with length {length} bytes'.format(name=file, length=len(uploaded[file])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file \"atis.test.pkl\" with length 277306 bytes\n",
            "Uploaded file \"atis.train.pkl\" with length 1566965 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScxIL5Q9jV0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14d335d6-358a-4c79-f732-4e7a93bfe79e"
      },
      "source": [
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "DATA_DIR=\".\"\n",
        "\n",
        "# Pickle 파일 로딩하기\n",
        "def load_ds(fname=os.path.join(DATA_DIR,'/atis.train.pkl'), verbose=True):\n",
        "    with open(fname, 'rb') as stream:\n",
        "        ds,dicts = pickle.load(stream)\n",
        "    if verbose:\n",
        "      print('Done  loading: ', fname)\n",
        "      print('      samples: {:4d}'.format(len(ds['query'])))\n",
        "      print('   vocab_size: {:4d}'.format(len(dicts['token_ids'])))\n",
        "      print('   slot count: {:4d}'.format(len(dicts['slot_ids'])))\n",
        "      print(' intent count: {:4d}'.format(len(dicts['intent_ids'])))\n",
        "    return ds,dicts\n",
        "  \n",
        "# Pickle 파일들을 배열로 전환하기\n",
        "def load_atis(filename, add_start_end_token=False, verbose=True):\n",
        "    train_ds, dicts = load_ds(os.path.join(DATA_DIR,filename), verbose)\n",
        "    t2i, s2i, in2i = map(dicts.get, ['token_ids', 'slot_ids','intent_ids'])\n",
        "    i2t, i2s, i2in = map(lambda d: {d[k]:k for k in d.keys()}, [t2i,s2i,in2i])\n",
        "    query, slots, intent =  map(train_ds.get, ['query', 'slot_labels', 'intent_labels'])\n",
        "\n",
        "    if add_start_end_token:\n",
        "        i2s[178] = 'BOS'\n",
        "        i2s[179] = 'EOS'\n",
        "        s2i['BOS'] = 178\n",
        "        s2i['EOS'] = 179\n",
        "\n",
        "    input_tensor = []\n",
        "    target_tensor = []\n",
        "    query_data = []\n",
        "    intent_data = []\n",
        "    slot_data = []\n",
        "    to_show = np.random.randint(0, len(query)-1, 5)\n",
        "    for i in range(len(query)):\n",
        "        input_tensor.append(query[i])\n",
        "        slot_text = []\n",
        "        slot_vector = []\n",
        "        for j in range(len(query[i])):\n",
        "            slot_text.append(i2s[slots[i][j]])\n",
        "            slot_vector.append(slots[i][j])\n",
        "        if add_start_end_token:\n",
        "            slot_text[0] = 'BOS'\n",
        "            slot_vector[0] = 178\n",
        "            slot_text[-1] = 'EOS'\n",
        "            slot_vector[-1]= 179\n",
        "        target_tensor.append(slot_vector)\n",
        "        q = ' '.join(map(i2t.get, query[i]))\n",
        "        query_data.append(q.replace('BOS', '').replace('EOS',''))\n",
        "        intent_data.append(i2in[intent[i][0]])\n",
        "        slot = ' '.join(slot_text)\n",
        "        slot_data.append(slot[1:-1])\n",
        "        if i in to_show and verbose:\n",
        "          print('Query text:', q)\n",
        "          print('Query vector: ', query[i])\n",
        "          print('Intent label: ', i2in[intent[i][0]])\n",
        "          print('Slot text: ', slot)\n",
        "          print('Slot vector: ', slot_vector)\n",
        "          print('*'*74)\n",
        "    query_data = np.array(query_data)\n",
        "    intent_data = np.array(intent_data)\n",
        "    slot_data = np.array(slot_data)\n",
        "    intent_data_label = np.array(intent).flatten()\n",
        "    return t2i, s2i, in2i, i2t, i2s, i2in, input_tensor, target_tensor, query_data, intent_data, intent_data_label, slot_data\n",
        "\n",
        "# ATIS Trainset 준비하기\n",
        "t2i_train, s2i_train, in2i_train, i2t_train, i2s_train, i2in_train, \\\n",
        "input_tensor_train, target_tensor_train, \\\n",
        "query_data_train, intent_data_train, intent_data_label_train, slot_data_train = load_atis('atis.train.pkl')\n",
        "\n",
        "# ATIS testset 준비하기\n",
        "t2i_test, s2i_test, in2i_test, i2t_test, i2s_test, i2in_test, \\\n",
        "input_tensor_test, target_tensor_test, \\\n",
        "query_data_test, intent_data_test, intent_data_label_test, slot_data_test = load_atis('atis.test.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  loading:  ./atis.train.pkl\n",
            "      samples: 4978\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n",
            "Query text: BOS what are the flights between pittsburgh and baltimore on august tenth EOS\n",
            "Query vector:  [178 916 228 827 429 259 682 215 247 654 243 821 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O O O B-fromloc.city_name O B-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 48, 128, 78, 128, 28, 27, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS i would like a schedule of flights from denver to san francisco on tuesday EOS\n",
            "Query vector:  [178 479 932 545 180 745 646 429 444 351 851 739 440 654 874 179]\n",
            "Intent label:  flight_time\n",
            "Slot text:  O O O O O B-flight_time O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_date.day_name O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 45, 128, 128, 128, 48, 128, 78, 125, 128, 26, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS show me the least expensive flight from miami to new york on a sunday with first class fare EOS\n",
            "Query vector:  [178 770 581 827 536 407 428 444 589 851 619 937 654 180 805 925 425 302\n",
            " 414 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O B-cost_relative I-cost_relative O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O B-depart_date.day_name O B-class_type I-class_type O O\n",
            "Slot vector:  [128, 128, 128, 128, 21, 93, 128, 128, 48, 128, 78, 125, 128, 128, 26, 128, 18, 92, 128, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS what is fare code f EOS\n",
            "Query vector:  [178 916 498 414 309 411 179]\n",
            "Intent label:  abbreviation\n",
            "Slot text:  O O O O O B-fare_basis_code O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 39, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS list flights from houston to memphis june twenty ninth EOS\n",
            "Query vector:  [178 549 429 444 476 851 587 508 881 626 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O B-fromloc.city_name O B-toloc.city_name B-depart_date.month_name B-depart_date.day_number I-depart_date.day_number O\n",
            "Slot vector:  [128, 128, 128, 128, 48, 128, 78, 28, 27, 95, 128]\n",
            "**************************************************************************\n",
            "Done  loading:  ./atis.test.pkl\n",
            "      samples:  893\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n",
            "Query text: BOS show me the cheapest round trip coach fare on twa from las vegas to detroit EOS\n",
            "Query vector:  [178 770 581 827 296 730 870 308 414 654 877 444 527 897 851 361 179]\n",
            "Intent label:  airfare\n",
            "Slot text:  O O O O B-cost_relative B-round_trip I-round_trip B-class_type O O B-airline_code O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O\n",
            "Slot vector:  [128, 128, 128, 128, 21, 66, 119, 18, 128, 128, 1, 128, 48, 110, 128, 78, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS list the distance in miles from new york 's la guardia airport to downtown new york city EOS\n",
            "Query vector:  [178 549 827 373 482 594 444 619 937   5 520 459 203 851 380 619 937 301\n",
            " 179]\n",
            "Intent label:  distance\n",
            "Slot text:  O O O O O O O B-fromloc.city_name I-fromloc.city_name I-fromloc.city_name B-fromloc.airport_name I-fromloc.airport_name I-fromloc.airport_name O O B-city_name I-city_name I-city_name O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 48, 110, 110, 47, 109, 109, 128, 128, 17, 91, 91, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS list wednesday night flights from oakland to salt lake city EOS\n",
            "Query vector:  [178 549 908 622 429 444 644 851 736 521 301 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O B-depart_date.day_name B-depart_time.period_of_day O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name O\n",
            "Slot vector:  [128, 128, 26, 33, 128, 128, 48, 128, 78, 125, 125, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS baltimore to kansas city economy EOS\n",
            "Query vector:  [178 247 851 511 301 391 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name B-economy O\n",
            "Slot vector:  [128, 48, 128, 78, 125, 37, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS please list all the flights from kansas city to chicago on june sixteenth EOS\n",
            "Query vector:  [178 688 549 207 827 429 444 511 301 851 297 654 508 774 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 48, 110, 128, 78, 128, 28, 27, 128]\n",
            "**************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w23tvRS7LgwI",
        "colab_type": "text"
      },
      "source": [
        "결과들은 다음과 같다.  \n",
        "Query Text: Query본 질문  \n",
        "Query Vector: 질문의 각각의 단어들을 벡터화  \n",
        "Intent Label: 질문의 의도 파악하기(이 데이터셋의 경우 flight, airfare 등등)  \n",
        "Slot Text: 문장 각각의 단어에서 중요한 단어들의 의도를 작성  \n",
        "Slot Vector: slot text들을 vector화  \n",
        "\n",
        "Query text들이 Intent 라벨들로 각각 바뀐 것을 볼 수 있습니다.  \n",
        "Pandas 라이브러리를 이용해 표로 바꿔보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF5cfBKtjv_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "ba59a64b-9250-43c6-a395-254cc0d2f525"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "df = pd.DataFrame({'query': query_data_train, 'intent': intent_data_train, 'slot filling': slot_data_train})\n",
        "\n",
        "df_small = pd.DataFrame(columns=['query','intent','slot filling'])\n",
        "j = 0\n",
        "for i in df.intent.unique():\n",
        "  df_small.loc[j] = df[df.intent==i].iloc[0]\n",
        "  j = j+1\n",
        "  \n",
        "df_small"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>intent</th>\n",
              "      <th>slot filling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i want to fly from boston at 838 am and arrive in denver at 1110 in the morning</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is the arrival time in san francisco for the 755 am flight leaving washington</td>\n",
              "      <td>flight_time</td>\n",
              "      <td>O O O B-flight_time I-flight_time O B-fromloc.city_name I-fromloc.city_name O O B-depart_time.time I-depart_time.time O O B-fromloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "      <td>airfare</td>\n",
              "      <td>B-cost_relative O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what kind of aircraft is used on a flight from cleveland to dallas</td>\n",
              "      <td>aircraft</td>\n",
              "      <td>O O O O O O O O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what kind of ground transportation is available in denver</td>\n",
              "      <td>ground_service</td>\n",
              "      <td>O O O O O O O O B-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>what 's the airport at orlando</td>\n",
              "      <td>airport</td>\n",
              "      <td>O O O O O B-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>which airline serves denver pittsburgh and atlanta</td>\n",
              "      <td>airline</td>\n",
              "      <td>O O O B-fromloc.city_name B-fromloc.city_name O B-fromloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>how far is it from orlando airport to orlando</td>\n",
              "      <td>distance</td>\n",
              "      <td>O O O O O B-fromloc.airport_name I-fromloc.airport_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>what is fare code h</td>\n",
              "      <td>abbreviation</td>\n",
              "      <td>O O O O B-fare_basis_code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>how much does the limousine service cost within pittsburgh</td>\n",
              "      <td>ground_fare</td>\n",
              "      <td>O O O O B-transport_type O O O B-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>please tell me how many nonstop flights there are from boston to atlanta</td>\n",
              "      <td>quantity</td>\n",
              "      <td>O O O O O B-flight_stop O O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>what city is the airport mco in</td>\n",
              "      <td>city</td>\n",
              "      <td>O O O O O B-fromloc.airport_code O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>flight numbers from columbus to minneapolis tomorrow</td>\n",
              "      <td>flight_no</td>\n",
              "      <td>O O O B-fromloc.city_name O B-toloc.city_name B-depart_date.today_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>how many seats in a 100</td>\n",
              "      <td>capacity</td>\n",
              "      <td>O O O O O B-aircraft_code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>give me the flights and fares on december twenty seventh from indianapolis to orlando</td>\n",
              "      <td>flight+airfare</td>\n",
              "      <td>O O O O O O O B-depart_date.month_name B-depart_date.day_number I-depart_date.day_number O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>show me all meals on flights from atlanta to washington</td>\n",
              "      <td>meal</td>\n",
              "      <td>O O O B-meal O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>what are the air restrictions on flights from pittsburgh to atlanta for the airfare of 416 dollars</td>\n",
              "      <td>restriction</td>\n",
              "      <td>O O O O O O O O B-fromloc.city_name O B-toloc.city_name O O O O B-fare_amount I-fare_amount</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>airline and flight number from columbus to minneapolis</td>\n",
              "      <td>airline+flight_no</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>what ground transportation is available from the pittsburgh airport to downtown and how much does it cost</td>\n",
              "      <td>ground_service+ground_fare</td>\n",
              "      <td>O O O O O O O B-fromloc.airport_name I-fromloc.airport_name O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>show me the costs and times for flights from san francisco to atlanta</td>\n",
              "      <td>airfare+flight_time</td>\n",
              "      <td>O O O O O B-flight_time O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>show me the cheapest fare in the database</td>\n",
              "      <td>cheapest</td>\n",
              "      <td>O O O B-cost_relative O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>i want to fly from detroit to st. petersburg on northwest airlines and leave around 9 am tell me what aircraft are used by this flight and tell me the flight number</td>\n",
              "      <td>aircraft+flight+flight_no</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-airline_name I-airline_name O O B-depart_time.time_relative B-depart_time.time I-depart_time.time O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                     query  ...                                                                                                                                                                                               slot filling\n",
              "0    i want to fly from boston at 838 am and arrive in denver at 1110 in the morning                                                                                        ...   O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day                                                      \n",
              "1    what is the arrival time in san francisco for the 755 am flight leaving washington                                                                                     ...   O O O B-flight_time I-flight_time O B-fromloc.city_name I-fromloc.city_name O O B-depart_time.time I-depart_time.time O O B-fromloc.city_name                                                           \n",
              "2    cheapest airfare from tacoma to orlando                                                                                                                                ...   B-cost_relative O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                             \n",
              "3    what kind of aircraft is used on a flight from cleveland to dallas                                                                                                     ...   O O O O O O O O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                             \n",
              "4    what kind of ground transportation is available in denver                                                                                                              ...   O O O O O O O O B-city_name                                                                                                                                                                             \n",
              "5    what 's the airport at orlando                                                                                                                                         ...   O O O O O B-city_name                                                                                                                                                                                   \n",
              "6    which airline serves denver pittsburgh and atlanta                                                                                                                     ...   O O O B-fromloc.city_name B-fromloc.city_name O B-fromloc.city_name                                                                                                                                     \n",
              "7    how far is it from orlando airport to orlando                                                                                                                          ...   O O O O O B-fromloc.airport_name I-fromloc.airport_name O B-toloc.city_name                                                                                                                             \n",
              "8    what is fare code h                                                                                                                                                    ...   O O O O B-fare_basis_code                                                                                                                                                                               \n",
              "9    how much does the limousine service cost within pittsburgh                                                                                                             ...   O O O O B-transport_type O O O B-city_name                                                                                                                                                              \n",
              "10   please tell me how many nonstop flights there are from boston to atlanta                                                                                               ...   O O O O O B-flight_stop O O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                 \n",
              "11   what city is the airport mco in                                                                                                                                        ...   O O O O O B-fromloc.airport_code O                                                                                                                                                                      \n",
              "12   flight numbers from columbus to minneapolis tomorrow                                                                                                                   ...   O O O B-fromloc.city_name O B-toloc.city_name B-depart_date.today_relative                                                                                                                              \n",
              "13   how many seats in a 100                                                                                                                                                ...   O O O O O B-aircraft_code                                                                                                                                                                               \n",
              "14   give me the flights and fares on december twenty seventh from indianapolis to orlando                                                                                  ...   O O O O O O O B-depart_date.month_name B-depart_date.day_number I-depart_date.day_number O B-fromloc.city_name O B-toloc.city_name                                                                      \n",
              "15   show me all meals on flights from atlanta to washington                                                                                                                ...   O O O B-meal O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                              \n",
              "16   what are the air restrictions on flights from pittsburgh to atlanta for the airfare of 416 dollars                                                                     ...   O O O O O O O O B-fromloc.city_name O B-toloc.city_name O O O O B-fare_amount I-fare_amount                                                                                                             \n",
              "17   airline and flight number from columbus to minneapolis                                                                                                                 ...   O O O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                                       \n",
              "18   what ground transportation is available from the pittsburgh airport to downtown and how much does it cost                                                              ...   O O O O O O O B-fromloc.airport_name I-fromloc.airport_name O O O O O O O O                                                                                                                             \n",
              "19   show me the costs and times for flights from san francisco to atlanta                                                                                                  ...   O O O O O B-flight_time O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name                                                                                                               \n",
              "20   show me the cheapest fare in the database                                                                                                                              ...   O O O B-cost_relative O O O O                                                                                                                                                                           \n",
              "21   i want to fly from detroit to st. petersburg on northwest airlines and leave around 9 am tell me what aircraft are used by this flight and tell me the flight number   ...   O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-airline_name I-airline_name O O B-depart_time.time_relative B-depart_time.time I-depart_time.time O O O O O O O O O O O O O O O \n",
              "\n",
              "[22 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYQiSJM4LlyJ",
        "colab_type": "text"
      },
      "source": [
        "#### 0번 행 데이터를 바탕으로 표를 해석해봅시다.  \n",
        "Query \"i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\":  \n",
        "오전 8시 38분에 보스턴에서 비행기를 타고 오전 11시 10에 덴버에 도착하고 싶다 라고 말합니다.  \n",
        "  \n",
        "모델은 이 Query의 intent를 비행(Flight)로 분류하였습니다.  \n",
        "모델은 Query의 구문을 분석하고, 쿼리를 이용하는 데 필요한 slot들을 모두 채워 이해해야 intent 결과를 낼 수 있습니다.  \n",
        "비록 각각의 단어들 \"I\", \"want\", \"to\", \"fly\", \"from\", \"at\", \"and\", \"arrive\", \"in\",\"the\"들은 맥락을 이해하는데 기여하지만 모델은 비행하려는 의도에 따라     \n",
        "필요한 entity들을 모두 충족해야 합니다.  \n",
        "\n",
        "이러한 의도를 충족하기 위해서는 출발도시 \"boston\"(B-fromloc.city), 출발 시간 \"838am\"(B-depart_time.time), 도착 도시 \"denver\" (B-toloc.city_name),  \n",
        "도착시간 \"11:10\"(B-arrive_time.time)그리고 추가 정보 \"morning) (B-arrive_time.period_of_day)를 모았습니다. \n",
        "\n",
        "이와 같이 129개의 slot 카테고리들이 이와같은 양상을 띄고 있습니다.  \n",
        "(추가. slot filling 의 0 처리는 의미없는 정보를 나타내며, 0 처리가 아닌 부분들은 intent를 만족하기 위한 정보들을 인덱싱화 한 것을 볼 수 있다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPtf84vBk5M9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "765b0d0a-7205-4b5a-cfca-c17ba18cf2d9"
      },
      "source": [
        "i2s_train_values = list(i2s_train.values())\n",
        "df3 = pd.DataFrame()\n",
        "for i in range(7):\n",
        "  df3[str(i)] = i2s_train_values[i*15:(i+1)*15]\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-aircraft_code</td>\n",
              "      <td>B-arrive_time.time_relative</td>\n",
              "      <td>B-depart_date.year</td>\n",
              "      <td>B-flight_time</td>\n",
              "      <td>B-return_date.day_name</td>\n",
              "      <td>B-today_relative</td>\n",
              "      <td>I-arrive_time.time_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-airline_code</td>\n",
              "      <td>B-booking_class</td>\n",
              "      <td>B-depart_time.end_time</td>\n",
              "      <td>B-fromloc.airport_code</td>\n",
              "      <td>B-return_date.day_number</td>\n",
              "      <td>B-toloc.airport_code</td>\n",
              "      <td>I-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-airline_name</td>\n",
              "      <td>B-city_name</td>\n",
              "      <td>B-depart_time.period_mod</td>\n",
              "      <td>B-fromloc.airport_name</td>\n",
              "      <td>B-return_date.month_name</td>\n",
              "      <td>B-toloc.airport_name</td>\n",
              "      <td>I-class_type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B-airport_code</td>\n",
              "      <td>B-class_type</td>\n",
              "      <td>B-depart_time.period_of_day</td>\n",
              "      <td>B-fromloc.city_name</td>\n",
              "      <td>B-return_date.today_relative</td>\n",
              "      <td>B-toloc.city_name</td>\n",
              "      <td>I-cost_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-airport_name</td>\n",
              "      <td>B-compartment</td>\n",
              "      <td>B-depart_time.start_time</td>\n",
              "      <td>B-fromloc.state_code</td>\n",
              "      <td>B-return_time.period_mod</td>\n",
              "      <td>B-toloc.country_name</td>\n",
              "      <td>I-depart_date.day_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B-arrive_date.date_relative</td>\n",
              "      <td>B-connect</td>\n",
              "      <td>B-depart_time.time</td>\n",
              "      <td>B-fromloc.state_name</td>\n",
              "      <td>B-return_time.period_of_day</td>\n",
              "      <td>B-toloc.state_code</td>\n",
              "      <td>I-depart_date.day_number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B-arrive_date.day_name</td>\n",
              "      <td>B-cost_relative</td>\n",
              "      <td>B-depart_time.time_relative</td>\n",
              "      <td>B-meal</td>\n",
              "      <td>B-round_trip</td>\n",
              "      <td>B-toloc.state_name</td>\n",
              "      <td>I-depart_date.today_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B-arrive_date.day_number</td>\n",
              "      <td>B-day_name</td>\n",
              "      <td>B-economy</td>\n",
              "      <td>B-meal_code</td>\n",
              "      <td>B-state_code</td>\n",
              "      <td>B-transport_type</td>\n",
              "      <td>I-depart_time.end_time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>B-arrive_date.month_name</td>\n",
              "      <td>B-day_number</td>\n",
              "      <td>B-fare_amount</td>\n",
              "      <td>B-meal_description</td>\n",
              "      <td>B-state_name</td>\n",
              "      <td>I-airline_name</td>\n",
              "      <td>I-depart_time.period_of_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>B-arrive_date.today_relative</td>\n",
              "      <td>B-days_code</td>\n",
              "      <td>B-fare_basis_code</td>\n",
              "      <td>B-mod</td>\n",
              "      <td>B-stoploc.airport_code</td>\n",
              "      <td>I-airport_name</td>\n",
              "      <td>I-depart_time.start_time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>B-arrive_time.end_time</td>\n",
              "      <td>B-depart_date.date_relative</td>\n",
              "      <td>B-flight</td>\n",
              "      <td>B-month_name</td>\n",
              "      <td>B-stoploc.airport_name</td>\n",
              "      <td>I-arrive_date.day_number</td>\n",
              "      <td>I-depart_time.time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>B-arrive_time.period_mod</td>\n",
              "      <td>B-depart_date.day_name</td>\n",
              "      <td>B-flight_days</td>\n",
              "      <td>B-or</td>\n",
              "      <td>B-stoploc.city_name</td>\n",
              "      <td>I-arrive_time.end_time</td>\n",
              "      <td>I-depart_time.time_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>B-arrive_time.period_of_day</td>\n",
              "      <td>B-depart_date.day_number</td>\n",
              "      <td>B-flight_mod</td>\n",
              "      <td>B-period_of_day</td>\n",
              "      <td>B-stoploc.state_code</td>\n",
              "      <td>I-arrive_time.period_of_day</td>\n",
              "      <td>I-economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>B-arrive_time.start_time</td>\n",
              "      <td>B-depart_date.month_name</td>\n",
              "      <td>B-flight_number</td>\n",
              "      <td>B-restriction_code</td>\n",
              "      <td>B-time</td>\n",
              "      <td>I-arrive_time.start_time</td>\n",
              "      <td>I-fare_amount</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>B-arrive_time.time</td>\n",
              "      <td>B-depart_date.today_relative</td>\n",
              "      <td>B-flight_stop</td>\n",
              "      <td>B-return_date.date_relative</td>\n",
              "      <td>B-time_relative</td>\n",
              "      <td>I-arrive_time.time</td>\n",
              "      <td>I-fare_basis_code</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               0  ...                             6\n",
              "0   B-aircraft_code               ...  I-arrive_time.time_relative \n",
              "1   B-airline_code                ...  I-city_name                 \n",
              "2   B-airline_name                ...  I-class_type                \n",
              "3   B-airport_code                ...  I-cost_relative             \n",
              "4   B-airport_name                ...  I-depart_date.day_name      \n",
              "5   B-arrive_date.date_relative   ...  I-depart_date.day_number    \n",
              "6   B-arrive_date.day_name        ...  I-depart_date.today_relative\n",
              "7   B-arrive_date.day_number      ...  I-depart_time.end_time      \n",
              "8   B-arrive_date.month_name      ...  I-depart_time.period_of_day \n",
              "9   B-arrive_date.today_relative  ...  I-depart_time.start_time    \n",
              "10  B-arrive_time.end_time        ...  I-depart_time.time          \n",
              "11  B-arrive_time.period_mod      ...  I-depart_time.time_relative \n",
              "12  B-arrive_time.period_of_day   ...  I-economy                   \n",
              "13  B-arrive_time.start_time      ...  I-fare_amount               \n",
              "14  B-arrive_time.time            ...  I-fare_basis_code           \n",
              "\n",
              "[15 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8xm57AtzvbQ",
        "colab_type": "text"
      },
      "source": [
        "위에서 말한 방법을 토대로 이러한 표로 나타낸 것을 보게 될 수 있다.\n",
        "(이 데이터들이 미리 token화 되어있습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvfEE6SsLscL",
        "colab_type": "text"
      },
      "source": [
        "##Tensor 생성하기  \n",
        "\n",
        "Query 벡터들을 만들어주고, slot 벡터들을 padding을 통해 최대길이까지 맞춰 Tensor들을 생성하게 됩니다.  \n",
        "*padding: 데이터들은 냅두고, 빈 공간들은 0으로 채워주는 방법\n",
        "\n",
        "우리는 targer slot을 위해 두 개의 tensor들을 제공하게 됩니다.  \n",
        "하나는 **teacher tensor**로, decoder에게 정확한 slot 결과를 도출하도록 도와줍니다.   \n",
        "다른 하나는 **true target tensor**로 teacher tensor를 도출해내기 위해 어떤 output을 decoder가 내야할지 정의해줍니다. \n",
        "  \n",
        "  \n",
        "  \n",
        "각 쿼리 벡터와 슬롯 벡터를 최대 길이로 채워 텐서를 만듭니다. 슬롯들에 2 개의 텐서를 제공합니다.  \n",
        "하나는 Teacher Tensor로 , 디코더가 올바른 출력 슬롯을 따르도록합니다.   \n",
        "다른 하나는 True Target Tensor이며, 이는 교사 텐서가 주어지면 디코더가 출력 해야하는 것을 정의합니다.  \n",
        "둘 사이의 유일한 차이점은 대상 텐서가 교사 텐서가 하나의 슬롯 레이블만큼 왼쪽으로 이동한다는 것입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKJNthg7lQvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4ee40269-502d-4ff4-bd28-e733522242c6"
      },
      "source": [
        "%tensorflow_version 1.x \n",
        "import tensorflow as tf\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "# Tensor 생성하기(+ Padding 처리해주기)\n",
        "def create_tensors(input_tensor, target_tensor, nb_sample=9999999, max_len=0):\n",
        "    len_input, len_target  = max_length(input_tensor), max_length(target_tensor)\n",
        "    len_input = max(len_input,max_len)\n",
        "    len_target = max(len_target,max_len)\n",
        "    \n",
        "\n",
        "    # 최대 길이에 따라 Padding 처리해주기\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=len_input,\n",
        "                                                                 padding='post')\n",
        "    #teacher forcing을 위한 tensor도 만들어주기\n",
        "    teacher_data = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=len_target , \n",
        "                                                                  padding='post')\n",
        "    #target data 생성해주기\n",
        "    target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "    target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "    target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "    \n",
        "    nb = len(input_data)\n",
        "    p = np.random.permutation(nb)\n",
        "    input_data = input_data[p]\n",
        "    teacher_data = teacher_data[p]\n",
        "    target_data = target_data[p]\n",
        "\n",
        "    return input_data[:min(nb_sample, nb)], teacher_data[:min(nb_sample, nb)], target_data[:min(nb_sample, nb)],len_input, len_target \n",
        "\n",
        "#create_tensors 실행\n",
        "input_data_train, teacher_data_train, target_data_train, \\\n",
        "                  len_input_train, len_target_train  = create_tensors(input_tensor_train, target_tensor_train)\n",
        "input_data_test, teacher_data_test, target_data_test, \\\n",
        "                 len_input_test, len_target_test  = create_tensors(input_tensor_test, target_tensor_test, max_len=len_input_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLbqDHAMihLe",
        "colab_type": "text"
      },
      "source": [
        "단어 크기를 계산하기 위해 우리는 train 단어들과 test 단어들을 결합합니다.  \n",
        "이 경우에는 input에는 943 개의 단어가 있고 output에는 129 개의 단어가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t2nvdtPlatl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "94ab025c-bdc2-4da3-b2c6-5e47b5059e53"
      },
      "source": [
        "def get_vocab_size(t2i_train, t2i_test, s2i_train, s2i_test):\n",
        "    vocab_in_size = len({**t2i_train, **t2i_test})\n",
        "    vocab_out_size = len({**s2i_train, **s2i_test})\n",
        "    return vocab_in_size, vocab_out_size\n",
        "  \n",
        "vocab_in_size, vocab_out_size = get_vocab_size(t2i_train, t2i_test, s2i_train, s2i_test)\n",
        "vocab_in_size, vocab_out_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 129)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbP7zddbMIEL",
        "colab_type": "text"
      },
      "source": [
        "## Slot Filling을 위한 Seq2Seq 모델 구축하기\n",
        "Seq2Seq 모델은 Encoder 및 Decoder에서 LSTM 구조를 사용하여 생성됩니다.  \n",
        "Input은 Encoder 모델에 맞춰 나타나는데,  \n",
        "encoder의 출력 구조에 맞춘  (batch_size, max_length, hidden_size)과  \n",
        "encoder의 hidden(hidden layer쪽) 상태에 맞춰 (batch_size, hidden_size) 나타납니다.  \n",
        "Encoder와 Decoder 모두 Embedding 레이어를 사용하여 문장을 투영하여 1024 개의 셀이 있는 한 방향의 LSTM 레이어로 공급됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_44LxdulvZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "d7eb72a4-0229-403f-87fe-19596407755b"
      },
      "source": [
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, CuDNNLSTM, Dropout\n",
        "\n",
        "#하이퍼 파라미터 정의하기\n",
        "BUFFER_SIZE = len(input_data_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "#Encoder Layer 쌓기\n",
        "encoder_inputs = Input(shape=(len_input_train,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "encoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "#Decoder Layer 쌓기\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "\n",
        "# 추론 능력 향상을 위한 추가적인 Dense Layer 정의하기:decoder에 연결된다.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "#DenseLayer 사이에 Drop-out을 추가하여 과적합을 방지합니다. (추가 설명 Dropout: unit들 중 일부만을 골라서 이용하는 과적합 방지의 한가지 방법이다.)\n",
        "decoder_out = decoder_d2(Dropout(rate=.4)(decoder_d1(Dropout(rate=.4)(decoder_lstm_out))))\n",
        "\n",
        "# 위의 Encoder와 Decoder를 합쳐 하나의 Training Model을 구축한다.\n",
        "# 이 모델은 3가지 Input이 들어가는 것을 잊지 말자!\n",
        "#  encoder_inputs=[batch,encoded_words] Input query들에서 추출\n",
        "#  teacher tensor: decoder_inputs=[batch,encoded_words] output slot들에서 추출\n",
        "#  target tensor : decoder_out=[batch,encoded_words] output slot들에서 추출\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_out)\n",
        "\n",
        "# sparse_categorical_crossentropy 함수를 통해 decoder_out을 one-hot의 긴 배열로 나타내는 것을 방지해준다.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 48, 256)      241408      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 256)    33024       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, 48, 1024), ( 5251072     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)        [(None, None, 1024), 5251072     embedding_2[0][0]                \n",
            "                                                                 cu_dnnlstm_1[0][1]               \n",
            "                                                                 cu_dnnlstm_1[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, 1024)   0           cu_dnnlstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1024)   1049600     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 1024)   0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 129)    132225      dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 11,958,401\n",
            "Trainable params: 11,958,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkqQ5T80MOkA",
        "colab_type": "text"
      },
      "source": [
        "### Seq2Seq 모델 훈련\n",
        "우리의 Output(slot 벡터들)은 one-hot 인코딩하지 않고, sparse_categorical_crossentropy를 손실함수로 사용하였다.   \n",
        "Adam을 최적화에 사용해 50 epoch에서, 3982 개의 훈련 샘플, 996 개의 검증 샘플을 사용하였습니다.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfl3Rc1Fkf3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "28d13b64-6e4c-4b53-cd4c-751c877a09b7"
      },
      "source": [
        "# epochs = 50\n",
        "epochs = 10\n",
        "\n",
        "#Train 데이터를 이용해 모델 학습하기와 함께 test 데이터를 이용해 검증하기\n",
        "history = model.fit([input_data_train, teacher_data_train], target_data_train,\n",
        "                 batch_size=BATCH_SIZE,\n",
        "                 epochs=epochs,\n",
        "                 validation_data=([input_data_test, teacher_data_test], target_data_test))\n",
        "                 \n",
        "def plot_training_accuracy(history):\n",
        "\n",
        "  acc = history.history['sparse_categorical_accuracy']\n",
        "  val_acc = history.history['val_sparse_categorical_accuracy']\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "\n",
        "  #결과를 matplotlib로 표현하기  \n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "plot_training_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4978 samples, validate on 893 samples\n",
            "Epoch 1/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2447 - sparse_categorical_accuracy: 0.9338 - val_loss: 0.2503 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 2/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2436 - sparse_categorical_accuracy: 0.9338 - val_loss: 0.2490 - val_sparse_categorical_accuracy: 0.9334\n",
            "Epoch 3/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.2480 - val_sparse_categorical_accuracy: 0.9331\n",
            "Epoch 4/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2401 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.2477 - val_sparse_categorical_accuracy: 0.9334\n",
            "Epoch 5/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2380 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.2513 - val_sparse_categorical_accuracy: 0.9338\n",
            "Epoch 6/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2373 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.2496 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 7/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2342 - sparse_categorical_accuracy: 0.9348 - val_loss: 0.2442 - val_sparse_categorical_accuracy: 0.9341\n",
            "Epoch 8/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2172 - sparse_categorical_accuracy: 0.9392 - val_loss: 0.2289 - val_sparse_categorical_accuracy: 0.9394\n",
            "Epoch 9/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.2005 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.2224 - val_sparse_categorical_accuracy: 0.9423\n",
            "Epoch 10/10\n",
            "4978/4978 [==============================] - 6s 1ms/step - loss: 0.1893 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.2098 - val_sparse_categorical_accuracy: 0.9446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4pIcv_PjN9h",
        "colab_type": "text"
      },
      "source": [
        "Epoch 10을 기준으로 나타난 표를 보면, epoch 7을 기준으로 Training과 Validation이 동일하게 올라가며 최대 95정확도가 오른 것을 볼 수 있다.  \n",
        "일반화가 적합하게 되었음을 나타낸다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl0I9uaQMcO6",
        "colab_type": "text"
      },
      "source": [
        "### Seq2Seq 모델을 사용한 추론\n",
        "Prediction에는 train과는 다른 두 가지 모델이 필요합니다.  \n",
        "Encoder와 Decoder를 분리해야합니다. 그런 다음 Encoder를 통해 전체 input 시퀀스들을 실행한 다음 Decoder로 한 단계식 예측하여 출력을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLkAy1CA9Cb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7fe16918-ea35-409d-ec0d-b966cd59f949"
      },
      "source": [
        "# 이전에 사용한 Encoder모델을 불러옵니다.\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder를 위해 새로운 tensor셋을 정의합니다.\n",
        "# 전에 사용하던 layer들은 사용하지 않습니다.(가중치, bias 모두 포함합니다.).\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# 각 단계마다 두 가지 상태 변수를 디코더에 강제로 공급해야합니다.\n",
        "state_input_h = Input(shape=(units,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])\n",
        "                  \n",
        "def preprocess_query(w):\n",
        "    w = w.rstrip().strip().lower()\n",
        "    w = \"BOS \" + w + \" EOS\"\n",
        "    return w\n",
        "  \n",
        "# 주어진 쿼리 (단지 문자열)를 단어 ID로 구성된 벡터로 변환합니다.\n",
        "# 지정된 언어를 사용하는데, 이것은 입력 (쿼리)에 사용될 수 있습니다.\n",
        "# Output is 1-D: [timesteps/words]\n",
        "def query_to_vector(query, len_input=len_input_train, t2i=t2i_train):\n",
        "    pre = preprocess_query(query)\n",
        "    vec = np.zeros(len_input)\n",
        "    query_list = [t2i[s] for s in pre.split(' ')]\n",
        "    for i,w in enumerate(query_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# 주어진 input을 바탕으로, encoder 모델 (infenc_model)과 decoder 모델(infmodel)을 정의합니다.\n",
        "# 예측된 slot 문장을 반환하도록 작성합니다.\n",
        "def predict_slots(input_query, infenc_model, infmodel, \n",
        "                  len_input=len_input_train, \n",
        "                  t2i=t2i_train, s2i=s2i_train, i2s=i2s_train,\n",
        "                  len_target=len_target_train,\n",
        "                  attention=False):\n",
        "    sent_len = len(input_query.split())\n",
        "    sv = query_to_vector(input_query, len_input, t2i)\n",
        "    #Encoder 모델에 사용될 수 있도록 reshape처리합니다. New shape=[samples,sequence length]\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\n",
        "    \n",
        "    i = 0\n",
        "    start_vec = s2i[\"O\"]\n",
        "    stop_vec = s2i[\"O\"]\n",
        "    # 다음 단어를 생성하기 위해 cur_vec를 디코더에 입력으로 지속적으로 공급합니다.\n",
        "    # \"EOS\"로 시작하여 cur_vec에 할당됩니다\n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"BOS\"\n",
        "    output_query = \"\"\n",
        "    # 모델이 \"EOS\"를 예측하거나 최대 목표 슬롯 길이의 끝에 도달하면 종료하기 전까지 계속 작용합니다.\n",
        "    while cur_word != \"EOS\" and i < (len_target-1) and i < sent_len+1:\n",
        "        i += 1\n",
        "        if cur_word != \"BOS\":\n",
        "            output_query = output_query + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        # Attention model을 이용해 적용합니다.\n",
        "        if attention:\n",
        "            x_in += [emb_out]\n",
        "        [nvec, sh, sc] = infmodel.predict(x=x_in)\n",
        "        # 모델의 출력은 가능한 모든 단어에 대해 하나의 spot이있는 방대한 softmax 벡터입니다. argmax ()를 사용하여 단어 ID로 변환합니다.\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = i2s[np.argmax(nvec[0,0])]\n",
        "    return output_query\n",
        "    \n",
        "input_query = \"what is the cheapest flight from boston to san francisco\"\n",
        "print(predict_slots(input_query, encoder_model, inf_model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " O O O B-cost_relative B-round_trip I-round_trip O O B-fromloc.city_name O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qJrx_WroB0v",
        "colab_type": "text"
      },
      "source": [
        "모델을 돌려보았을 때 cheapest, flight, boston, san franciso와 같은 Slot들을 모두 알아내는 높은 성능을 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8FYUdAChL0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "22ab69f1-0700-4692-f870-1ecac20ca465"
      },
      "source": [
        "import nltk\n",
        "def evaluate_slot_filling(queries, true_slots,\n",
        "                          len_input=len_input_test, \n",
        "                          t2i=t2i_test, s2i=s2i_test, i2s=i2s_test,\n",
        "                          len_target=len_target_test):\n",
        "  predicted_slots = []\n",
        "  for q in queries:\n",
        "    s = predict_slots(q, encoder_model, inf_model,\n",
        "                      len_input, \n",
        "                      t2i, s2i, i2s,\n",
        "                      len_target)\n",
        "    predicted_slots.append(s)\n",
        "  # calculate BLEU score\n",
        "  print('BLEU-1: %f' % nltk.translate.bleu_score.corpus_bleu(true_slots, predicted_slots, weights=(1.0, 0, 0, 0)))\n",
        "  print('BLEU-2: %f' % nltk.translate.bleu_score.corpus_bleu(true_slots, predicted_slots, weights=(0.5, 0.5, 0, 0)))\n",
        "  print('BLEU-3: %f' % nltk.translate.bleu_score.corpus_bleu(true_slots, predicted_slots, weights=(0.3, 0.3, 0.3, 0)))\n",
        "  print('BLEU-4: %f' % nltk.translate.bleu_score.corpus_bleu(true_slots, predicted_slots, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "  \n",
        "evaluate_slot_filling(query_data_test, slot_data_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.200123\n",
            "BLEU-2: 0.447351\n",
            "BLEU-3: 0.617148\n",
            "BLEU-4: 0.668843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOjFRFiSjaeY",
        "colab_type": "text"
      },
      "source": [
        "이제 예측 슬롯 채우기와 실제 슬롯 채우기 사이의 n-gram 수를 비교하여  \n",
        "번역 품질을 측정하는 데 사용되는 BLEU 알고리즘 (BiLingual Evaluation Understudy)을 사용하여 전체 테스트 데이터 세트에 대해 훈련 된 모델을 평가합니다.  \n",
        "예측 된 슬롯과 실제 슬롯간에 4-gram 그룹을 각각 비교할 때 전체 모델이 매우 잘 수행되고 있음을 나타냅니다.\n"
      ]
    }
  ]
}