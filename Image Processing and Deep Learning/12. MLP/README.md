# MLP: Maching Learning Perceptron

Two_layer_net.ipynb
	1) Small Net
		(1) Forward pass: Compute Scores/Loss
		(2) Backward Pass
		(3) Train the Network
	2) Cifar 10 dataset
		(1) Load the data
		(2) Train the Network
		(3) Debug the Training
		(4) Tune your hyperparameters
    The following modifications are reflected.
    1. The one with the most highest accuracy.
    2. Learning rate: increased learning_rates
    3. hidden_sizes: increased hidden_size
		(5) Run on the Test set
