{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "BERT Tutorial (Kor.).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISd77k5kmD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3iUQNCRQOUz",
        "colab_type": "text"
      },
      "source": [
        "# **BERT 톺아보기**\n",
        "BERT(이하 버트, Bidirectional Encoder Representations from Trsnaformer) 모델은 18년 10월에 논문이 공개된 구글의 새로운 Language Representation Model 이다. \n",
        "\n",
        " 기존의 ELMo 모델은 특징(Feature) 기반 전이학습으로, 단어(토큰)에 대한 특징 벡터를 훈련하는 방법이다. 이와는 달리 BERT는 파인 튜닝(Fine-Tuning) 기반 전이학습으로 이루어진다. 즉, \n",
        " 1. **(Wikipedia와 같은) 큰 텍스트 코퍼스를 이용해 Pre-training한 모델에 기반해**\n",
        " 2. **실제 자연 언어 처리 태스크에 적용**  \n",
        " \n",
        " 하는 방식으로 이루어진다.  \n",
        " \n",
        "   \n",
        " 본 Colab Notebook에서는 BERT가 진행되는 순서를 찬찬히 설명하고, Pre-training을 직접해보는 실습까지 담았다. 순서는 다음과 같다.\n",
        "\n",
        "\n",
        "**- BERT 따라가기**\n",
        "1. Input Embeddings\n",
        "2. Pre-training\n",
        "3. Fine-tuning  \n",
        "\n",
        "**- 실습단계: Next Sentence Prediction 구현해보기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atiLTTobSqRs",
        "colab_type": "text"
      },
      "source": [
        "# 1. Model Architecture\n",
        "\n",
        "본격적으로 들어가기 전에 모델 구조를 간단히 보도록 하자. \n",
        "\n",
        "- BERT는 크기에 따라 다른 구조를 제공한다.\n",
        "- BERT_base : L=12, H=768, A=12, Total Parameters = 110M\n",
        "- BERT_large : L=24, H=1024, A=16, Total Parameters = 340M\n",
        "- L : transformer block의 layer 수, H : hidden size, A : self-attention heads 수, feed-forward/filter size = 4H\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"![image.png]()https://mino-park7.github.io/images/2019/02/%EA%B7%B8%EB%A6%BC8-ablation-result3.png\" width = 600px align=\"center\">  </p>  \n",
        "Pre-trained 모델도 종류별로 있어서, 추가로 이들의 Accuracy 정도도 확인해 볼 수 있다.\n",
        "<p align=\"center\">\n",
        "<img src=\"https://mino-park7.github.io/images/2019/02/%EA%B7%B8%EB%A6%BC8-ablation-result3.png\" width = 300px align=\"center\">  </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojmq-TYDMLZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#모델을 위해 필요한 라이브러리 import하기\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# pre-trained model tokenizer 호출하기\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzV5i2Y8QOU0",
        "colab_type": "text"
      },
      "source": [
        "# 2. Input Embeddings\n",
        "\n",
        "**들어가기 전에..**  \n",
        "문장을 구성하기 위해 Input에 어떤 정보를 넣는게 좋을까?  \n",
        "문장들의 Token들과 이에 관한 문장 안의 Token들의 위치 정보나, 문장과 문장 간의 정보를 나타내는 정보들이 들어갈 것이다.   \n",
        "\n",
        "\n",
        "**들어가기**  \n",
        "BERT에서는 Input에는 어떠한 정보를 넣는지 살펴보자.  \n",
        "Input을 만들 때 문장 자체의 정보를 삽입하는 것이므로 모든 조건이 고려되야만 할 것이다.  BERT에는 3가지 정보가 들어간다.  \n",
        "  \n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://user-images.githubusercontent.com/1250095/50039788-8e4e8a00-007b-11e9-9747-8e29fbbea0b3.png\" width = 800px align=\"center\">  </p>  \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "Embedding을 위한 Input에는 BookCorpus와 Wikipedia 문장들을 포함해 총 3.3억개의 단어를 바탕으로 임베딩이 진행되었다.  \n",
        "**Input Embedding = Token Embedding + Segment Embedding + Position Embedding**이며, 언어의 특성을 파악하기 위한 조건들을 바탕으로 정해졌다. 각각의 Embedding을 하나하나 살펴보자. 이해를 위해 다음과 같은 문장을 토대로 설명하고자 한다.  \n",
        "시작하기 전에 적용할 텍스트 2개를 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAjhXsljg25h",
        "colab_type": "code",
        "outputId": "075092d3-5980-482f-cbd0-22e18d893016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# \"bank\"을 여러 token으로 가지고 있는 문장을 밑 실습에서 사용하게 된다.\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
        "       \"fishing on the Mississippi river bank.\"\n",
        "\n",
        "# 문장의 시작을 의미하는 [CLS]와 문장의 끝(분리)을 나타내는 [SEP]을 추가해준다.\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "print(marked_text)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvdndSVOgo5D",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Token Embedding\n",
        "Token Embedding은 문장을 토큰으로 나누는 과정을 말한다. 여기서는 Word Piece Model을 이용하여 구현하였다. 이 모델은 제한적인 vocabulary units, 정확히는 단어를 표현할 수 있는 subwords units 으로 모든 단어를 표현한다.  \n",
        "다음의 적용된 예시를 보도록 하자. 문장을 다음의 요소들로 나눈다면 이 유닛들은 의미를 보존하면서 재활용 될 수 있다.\n",
        "\n",
        "```\n",
        "공연은 끝났어 -> ['공연-' + '-은' + '끝-' + '-났어']\n",
        "공연을 끝냈어 -> ['공연-' + '-을' + '끝-' + '-냈어']\n",
        "개막을 해냈어 -> ['개막-' + '-을' + '해-' + '-냈어']\n",
        "```\n",
        "\n",
        "위에 예제로 사용된 문장과 달리 문장이 복잡한 상황을 살펴보자.  marked_text_a와 marked_text_b에 적용한 코드는 다음과 같다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxTBj1ocDvvg",
        "colab_type": "code",
        "outputId": "e76c91a2-9c1a-4e4a-82d2-d14ff4062879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "raw_text_a = \"Seahorses dreamed about word embeddings and artificial intelligence\"\n",
        "raw_text_b = \"Seahorse is a smart animal\"\n",
        "marked_text_a = \"[CLS] \" + raw_text_a + \" [SEP]\"\n",
        "marked_text_b = \"[CLS] \" + raw_text_b + \" [SEP]\"\n",
        "print(marked_text_a)\n",
        "print(marked_text_b)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Seahorses dreamed about word embeddings and artificial intelligence [SEP]\n",
            "[CLS] Seahorse is a smart animal [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9osDpuoqgjLC",
        "colab_type": "code",
        "outputId": "0ca04946-be97-4313-a752-1509d3a54cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "tokens_a = tokenizer.tokenize(marked_text_a)\n",
        "tokens_b = tokenizer.tokenize(marked_text_b)\n",
        "print(marked_text_a)\n",
        "print(tokens_a)\n",
        "print(marked_text_b)\n",
        "print(tokens_b)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Seahorses dreamed about word embeddings and artificial intelligence [SEP]\n",
            "['[CLS]', 'sea', '##horse', '##s', 'dreamed', 'about', 'word', 'em', '##bed', '##ding', '##s', 'and', 'artificial', 'intelligence', '[SEP]']\n",
            "[CLS] Seahorse is a smart animal [SEP]\n",
            "['[CLS]', 'sea', '##horse', 'is', 'a', 'smart', 'animal', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3oRmywxhiCw",
        "colab_type": "text"
      },
      "source": [
        "이와 같이 Token들로 나누어진 걸 볼 수 있다. Token들 중에 간간히 나오는 ## 표시는 이 단어는 어떤 단어의 일부 즉, subword라는 뜻을 말한다. Bert에서는 단어를 검색하는 방식으로 진행되는데, 전체 단어가 BERT vocab에 없으면 vocab에서 찾을 때까지 철자 하나씩까지도 쪼개는 방식으로 진행된다.  \n",
        "여기서 나온 Seahorse는 본 단어에서 Sea와 ##horse(2개의 Subword들)로 쪼개진 것을 알 수 있다.   \n",
        "\n",
        "우리가 적용한 코드는 이렇게 적용된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NO3UORiD4PC",
        "colab_type": "code",
        "outputId": "9d06f003-2cb6-42c7-a239-7cfc1e45a211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "print(tokenized_text)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeW0yFe3BK_i",
        "colab_type": "code",
        "outputId": "25ace65c-4b3e-4b4f-a0f4-496c8f6bd29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "after         2,044\n",
            "stealing     11,065\n",
            "money         2,769\n",
            "from          2,013\n",
            "the           1,996\n",
            "bank          2,924\n",
            "vault        11,632\n",
            ",             1,010\n",
            "the           1,996\n",
            "bank          2,924\n",
            "robber       27,307\n",
            "was           2,001\n",
            "seen          2,464\n",
            "fishing       5,645\n",
            "on            2,006\n",
            "the           1,996\n",
            "mississippi   5,900\n",
            "river         2,314\n",
            "bank          2,924\n",
            ".             1,012\n",
            "[SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFTt7W67gak_",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Segment Embedding\n",
        "Segment Embedding에서는 문장과 문장간의 관계를 나타낸다. 문장이 두개로 이어진 Input에서는 Segment ID는 첫 문장에는 0, 다음 문장은 1로 준다. 문장이 하나인 경우에는 Segment ID를 모두 1로 준다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vTd4y4eEK7p",
        "colab_type": "code",
        "outputId": "db70b398-3818-421b-9566-db6db9ebedff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#한 문장이  22개의 토큰으로 이루어져 있으므로, 모든 token에는 1의 값이 부여된다.\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "print (segments_ids)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY_IkCDziDAd",
        "colab_type": "code",
        "outputId": "b2eda6a6-a684-40d5-9552-0cb434e5d3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "raw_text_b = \"Seahorse is a smart animal\"\n",
        "marked_text_b = raw_text_b + \" [SEP]\"\n",
        "tokens_b = tokenizer.tokenize(marked_text_b)\n",
        "print(tokens_b)\n",
        "\n",
        "tokens = []\n",
        "input_type_ids = []\n",
        "\n",
        "#두 문장을 가지고 있으므로 앞에는 0 뒤에는 1을 붙여준다.\n",
        "for token in tokens_a:\n",
        "    tokens.append(token)\n",
        "    input_type_ids.append(0)\n",
        "\n",
        "if tokens_b:\n",
        "    for token in tokens_b:\n",
        "        tokens.append(token)\n",
        "        input_type_ids.append(1)\n",
        "        \n",
        "print(\"tokens:\", tokens)   \n",
        "print(\"type_ids:\", input_type_ids)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sea', '##horse', 'is', 'a', 'smart', 'animal', '[SEP]']\n",
            "tokens: ['[CLS]', 'sea', '##horse', '##s', 'dreamed', 'about', 'word', 'em', '##bed', '##ding', '##s', 'and', 'artificial', 'intelligence', '[SEP]', 'sea', '##horse', 'is', 'a', 'smart', 'animal', '[SEP]']\n",
            "type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4vBMCWqhwwC",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Position Embedding\n",
        "Position Embedding에서는 한 문장 내 특정 토큰의 순서를 보여준다.  \n",
        "다음과 같은 코드를 이용해 위치를 token화 할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQLGIcUaEnIz",
        "colab_type": "code",
        "outputId": "9e5321a1-3881-46db-ae15-90e99cd2e167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wkWsU-Hh8p2",
        "colab_type": "text"
      },
      "source": [
        "총 세가지 Embedding 정보를 이용해 Input Data를 형성하였고, 여기에 더해 Layer Normalization과 DropOut의 기법도 사용되었다.  \n",
        "이렇게 나온 Input Embedding은 Pre-training에 사용된다.\n",
        "\n",
        "**추가** 기존 임베딩 VS BERT 임베딩\n",
        "- 기존 임베딩은 문맥에 상관없이 같은 단어면 항상 같은 임베딩\n",
        "- Bert 임베딩은 문맥에 따라 다른 임베딩 양상을 보인다. 동음이의어뿐만 아니라, 문맥이 달라지면 같은 의미의 단어도 임베딩이 달라진다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAVe3kWNQOU1",
        "colab_type": "text"
      },
      "source": [
        "# 2. Pre-training\n",
        "\n",
        "<img src=\"https://blog.pingpong.us/images/2020.01.03.ml-transformer/transformer.png\" width = 250px align=\"right\">  \n",
        "\n",
        "주어진 Embedding된 Input들을 토대로 사전학습을 어떻게 하는지 알아보자.  \n",
        "BERT는 Pre-training을 위해 성능이 높은 *Transformer*구조를 참고하였는데, 왼쪽에 나온 Transformer 모델 중 왼쪽 Encoder 블록만을 취해 적용하는 방법을 택하였다. 이를 바탕으로 Input을 어떤 방식으로 학습하는지 알아보자.\n",
        "BERT는 총 두가지 방법을 통해 이루어진다.  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHEXDoh2QXcg",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 MLM (Masked Language Model)\n",
        ": input에서 무작위하게 몇개의 token을 mask(가려준다)해준다. Input 전체와 mask된 token을 한번에 Transformer encoder에 넣게되면  \n",
        "Masked된 Token을 맞추는 일종의 빈칸채우기와 같은 train을 시작한다.다음 예시를 보며 어떻게 변형하는지 살펴보자.\n",
        "\n",
        "  \n",
        "\n",
        "**예시**\n",
        "다음과 같은 문장을 넣는다고 가정해보자.  \n",
        "All good things which exist are the fruits of originality.\n",
        "```\n",
        "<Deeply Bidirectional> \n",
        "    All good things which [MASK] are the fruits of originality.\n",
        "    All good [MASK] which exist are the fruits of originality.\n",
        "    All good things which exist are the [MASK] of originality.\n",
        "    All [MASK] things which exist are the fruits of originality.\n",
        "\n",
        "<Left to Right>\n",
        "    All\n",
        "    All good\n",
        "    All good things\n",
        "    All good things which\n",
        "        ...\n",
        "\n",
        "<Right to Left>\n",
        "                                                    originality\n",
        "                                                 of originality\n",
        "                                          fruits of originality\n",
        "                                      the fruits of originality\n",
        "                                        ...\n",
        "```\n",
        "\n",
        "\n",
        "Input의 15% 단어들을 뽑아 학습하면서, 전체 문장의 특성의 확인이 가능해진다. 이러한 Deeply Bidirectional 학습 방식은 기존의 한 방향으로만 작용하는 left-to-right와 right-to-left의 방식과 다르게 자유롭게 문장 안에서의 학습이 가능하다.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN_AJDXGQb2M",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Next Language Prediction  \n",
        ": 간단하게, 두 문장을 pre-training시에 같이 넣어줘, 입력값으로 들어간 두 문장이 이어진 문장인지,  \n",
        "아니면 관계없는 문장인지를 예측하는 binary classification task를 수행한다.\n",
        "  \n",
        "\n",
        "**예시** 어떤 문장이 다음에 나타날 수 있는지 예측해보자.\n",
        "\n",
        "\n",
        "```\n",
        "Input = [CLS] The man went to [MASK] store [SEP] He bought a gallon [MASK] milk [END]\n",
        "Label = IsNext\n",
        "\n",
        "Input = [CLS] The man went to the store [SEP] Penguin [MASK] are flight ##less birds [END]\n",
        "Label = NotNext\n",
        "```\n",
        "\n",
        "pre-training시에는 50:50 비율로 실제로 이어지는 두 문장과 랜덤하게 추출된 두 문장을 넣어줘서 BERT가 맞추게 시킨다. 이러한 task는 실제 Natural Language Inference와 같은 task를 수행할 때 도움이 된다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTa89AC5QOU1",
        "colab_type": "text"
      },
      "source": [
        "# 3. Fine-tuning\n",
        "\n",
        "Pre-training을 끝내게 된다면, Fine-tuning에서는 모델을 바탕으로 특정 문제를 해결하는 task들을 하게 된다.  \n",
        "작업에 따라 다른 방향과 모델로 Tuning이 이루어지며, Task 종류는 다음과 같다.  \n",
        "\n",
        "<p align = \"center\">\n",
        "<img src=\"https://mino-park7.github.io/images/2019/02/%EA%B7%B8%EB%A6%BC4-bert-experiment-result.png\" width =700px align=\"center\"></p>\n",
        "\n",
        "- Text Similarity: 두 발화(문장)가 같은 의미인지 구분하는 binary classification 문제를 말한다. \n",
        "- Word Similarity: 문장 안에 있는 여러 개의 동일한 단어가 같은 의미인지 구분하는 분류 문제를 말한다.\n",
        "- Reply Matching: 두 발화가 자유럽게 이어지는지 이어지는지 구분하는 binary classification 문제를 말한다.\n",
        "- Intent Classification:여러 턴의 발화들이 주어졌을 때, 사전에 정의된 답변 class 중 다음에 올 수 있는 답변을 예측하는 multi-class classification 문제를 말한다. \n",
        "\n",
        "#### 밑 실습에는 Pre-trained BERT 모델을 이용해 문장을 fine-tuning 학습시켜 Word Similarity Task을 수행한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voF-0grOJNxO",
        "colab_type": "text"
      },
      "source": [
        "# 4. BERT 모델을 이용해 단어의 유사성 체크해보기: Pre-trained Model 활용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3plCrIRMGra",
        "colab_type": "text"
      },
      "source": [
        "Pre-trained model을 통해 문장을 학습시켜 보자.\n",
        "먼저 해당하는 Input을 Pytorch Tensor로 변환하는 작업이 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4gQr_d2Ee29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력값들을 모두 Model에 들어갈 Tensor(tokens_tensors, segments_tensors)로 만들어준다.\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r-juXIYMSDs",
        "colab_type": "text"
      },
      "source": [
        "#### Pretrained Model 살펴보기\n",
        "그리고 우리가 사용할 Pre-trained Bert를 꺼내본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkstXOR1p-Yw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f7e46a5-6541-4ca6-ddbe-0cdd111af8c1"
      },
      "source": [
        "#pre-trained model 부르기\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True,\n",
        "                                  )\n",
        "\n",
        "#Forward만 행하는 \"evaluation\" 모드로 변경해준다.\n",
        "model.eval()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwmBEpb-Ef4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력값을 BERT 모델을 넣어준다.\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPyqgGnwIU6f",
        "colab_type": "text"
      },
      "source": [
        "#### Encoded_layer 분석하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11wPEFqOI1RJ",
        "colab_type": "code",
        "outputId": "293f4f8d-f19f-42e3-a755-317765a9e733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 22\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdDfEpcLMnOL",
        "colab_type": "text"
      },
      "source": [
        "현재 모델인 Encoded_layers의 구조를 살펴보자. \n",
        "\n",
        "1) layer 개수 : len(encoded_layers) # 12개\n",
        "\n",
        "2) batch 개수 : len(encoded_layers[0]) # 하나의 문장\n",
        "\n",
        "3) 단어/토큰 개수 :  len(encoded_layers[0][0]) # batch 1개인 하나의 문장에 있는 22개의 토큰\n",
        "\n",
        "4) 은닉 상태 차원(hidden units/features) : len(encoded_layers[0][0][0]) # 768개의 features\n",
        "\n",
        "총 202,752개의 값들로 input으로 넣은 하나의 문장을 표현한다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QJpUkhjJPJT",
        "colab_type": "text"
      },
      "source": [
        "Encoded_layer에 존재하는 layer와 토큰 값들을 표로 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUhlVrW6I3P_",
        "colab_type": "code",
        "outputId": "3b00c548-5610-4213-e8fa-9275d93bdecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 5\n",
        "vec = hidden_states[layer_i][batch_i][token_i]\n",
        "\n",
        "# vec정보 즉,하나의 tensor로 합쳐진 정보를 분포에 나타내본다.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAI/CAYAAAC4QOfKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVxElEQVR4nO3df4xl93nX8c+DJwkVBdLgqbHimHFVl8qhxEFbK6hFKHaTurjUBtooFYJFWFpRCkogqEwShFQJpE2LmlYI/rDqqAtKSdImwVanQI2bUkDE6To/mjhuiBs2NI4Tb0qipkKkcvPwx1yna++uZ56dH/fuzuslWXPPuXfmPv5qd+a95945p7o7AADs3h9a9gAAAJcbAQUAMCSgAACGBBQAwJCAAgAYElAAAENrh/lkV199dW9sbBzmUwIAXJKHH374C929fqH7DjWgNjY2cvr06cN8SgCAS1JVn77YfV7CAwAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAoDL3MbmVjY2t5Y9xpEioAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABhaW/YAAMD+2Njc+trtMyfvWOIkVz5HoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAobXdPKiqziT5cpLfT/JUdx+rqhcleWeSjSRnkrymu794MGMCAKyOyRGoV3b3zd19bLG9meTB7r4xyYOLbQCAK95eXsK7M8mpxe1TSe7a+zgAAKtvtwHVSX6pqh6uqhOLfdd09xOL259Lcs2+TwcAsIJ29R6oJN/Z3Y9X1TcmeaCqfuPcO7u7q6ov9ImL4DqRJNdff/2ehgUAWAW7OgLV3Y8vPj6Z5L1Jbkny+aq6NkkWH5+8yOfe093HuvvY+vr6/kwNALBEOwZUVf2RqvqjT99O8uokH0tyf5Lji4cdT3LfQQ0JALBKdvMS3jVJ3ltVTz/+Z7v7P1bVryV5V1XdneTTSV5zcGMCAKyOHQOquz+V5GUX2P/bSW47iKEAAFaZM5EDAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQBXoI3NrWxsbu24j0sjoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwtLbsAQCAg+PEmQfDESgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoADjCNja3nGzzEggoAIAhAQUAMCSgAACGBBQAwNCuA6qqrqqqD1XVLyy2b6iqh6rqsap6Z1U9/+DGBABYHZMjUK9L8ug5229J8tbu/uYkX0xy934OBgCwqnYVUFV1XZI7kvz0YruS3Jrk5xcPOZXkroMYEABg1ez2CNRPJvmRJF9dbP+JJF/q7qcW259J8uJ9ng0AYCXtGFBV9b1Jnuzuhy/lCarqRFWdrqrTZ8+evZQvAQAsOPHlatjNEajvSPJ9VXUmyTuy/dLdTyV5YVWtLR5zXZLHL/TJ3X1Pdx/r7mPr6+v7MDIAwHLtGFDd/cbuvq67N5K8Nskvd/dfT/K+JN+/eNjxJPcd2JQAACtkL+eB+sdJ/mFVPZbt90Tduz8jAQCstrWdH/IHuvtXkvzK4vanktyy/yMBAKw2ZyIHABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADC0tuwBAIC5jc2tZY9wpDkCBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhJ9IEgCPmQifhPHffmZN3HOY4lyVHoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACG1pY9AADw3DY2t5Y9As/iCBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIZ2DKiq+sNV9YGq+khVPVJVP7rYf0NVPVRVj1XVO6vq+Qc/LgDA8u3mCNRXktza3S9LcnOS26vqFUnekuSt3f3NSb6Y5O6DGxMAYHXsGFC97XcXm89b/NdJbk3y84v9p5LcdSATAgCsmF29B6qqrqqqDyd5MskDSX4zyZe6+6nFQz6T5MUHMyIAwGrZVUB19+93981JrktyS5Jv3e0TVNWJqjpdVafPnj17iWMCAIdlY3MrG5tbyx5jpY1+C6+7v5TkfUn+fJIXVtXa4q7rkjx+kc+5p7uPdfex9fX1PQ0LALAKdvNbeOtV9cLF7a9L8qokj2Y7pL5/8bDjSe47qCEBAFbJ2s4PybVJTlXVVdkOrnd19y9U1ceTvKOq/lmSDyW59wDnBABYGTsGVHf/epKXX2D/p7L9figAgCPFmcgBAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAKyQjc2tbGxuLXsMdiCgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADC0tuwBAIDzOZnmanMECgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBobdkDAMBRt7G5tewRGHIECgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIZ2DKiqeklVva+qPl5Vj1TV6xb7X1RVD1TVJxcfv+HgxwUAWL7dHIF6KskbuvumJK9I8sNVdVOSzSQPdveNSR5cbAMAXPF2DKjufqK7P7i4/eUkjyZ5cZI7k5xaPOxUkrsOakgAgFUyeg9UVW0keXmSh5Jc091PLO76XJJr9nUyAIAVtbbbB1bV1yd5d5LXd/fvVNXX7uvurqq+yOedSHIiSa6//vq9TQsAHJqNza2v3T5z8o4lTrJ6dnUEqqqel+14ent3v2ex+/NVde3i/muTPHmhz+3ue7r7WHcfW19f34+ZAQCWaje/hVdJ7k3yaHf/xDl33Z/k+OL28ST37f94AACrZzcv4X1Hkr+R5KNV9eHFvjclOZnkXVV1d5JPJ3nNwYwIALBadgyo7v5vSeoid9+2v+MAAKw+ZyIHABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAobVlDwAArL6Nza3z9p05eccSJlkNjkABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwNDasgcAgKNqY3Nr2SPsybnznzl5xxInOXyOQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgyIk0AeCAXO4nypy40P/rlXxyTUegAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGBJQAABDAgoAYGjHgKqqt1XVk1X1sXP2vaiqHqiqTy4+fsPBjgkAsDp2cwTqZ5Lc/qx9m0ke7O4bkzy42AYAOBJ2DKju/tUk/+dZu+9Mcmpx+1SSu/Z5LgCAlXWp74G6prufWNz+XJJr9mkeAICVt+c3kXd3J+mL3V9VJ6rqdFWdPnv27F6fDgBg6S41oD5fVdcmyeLjkxd7YHff093HuvvY+vr6JT4dAMDquNSAuj/J8cXt40nu259xAABW325OY/DvkvyPJH+6qj5TVXcnOZnkVVX1ySTftdgGADgS1nZ6QHf/4EXuum2fZwEAuCw4EzkAwJCAAgAYElAAAEMCCgBgaMc3kQMAMxubW8segQPmCBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAHAgNja3rtiTigooAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAytLXsAALjcnHtyyDMn71jiJCyLI1AAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhgQUAMCQgAIAGHIiTQDgQF2JJx51BAoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQ06kCQAcusv95JqOQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAYElAAAEMCCgBgSEABwB5sbG4946SQzF2OayigAACGBBQAwJCAAgAYElAAAEMCCgBgSEABAAwJKACAIQEFADAkoAAAhtaWPQAAcHRMzzh+7uPPnLxjv8e5ZI5AAQAMCSgAgCEBBQAwJKAAAIYEFADAkIACABgSUAAAQwIKAGDIiTQB4Dns9kSO0xNE8txWfT0dgQIAGBJQAABDAgoAYEhAAQAMCSgAgCEBBQAwJKAAAIYEFADA0BV3Is3dnvAMAC7mYidxXPWTO17pnl7/Vfj57ggUAMCQgAIAGBJQAABDAgoAYGhPAVVVt1fVJ6rqsara3K+hAABW2SUHVFVdleRfJfmeJDcl+cGqumm/BgMAWFV7OQJ1S5LHuvtT3f17Sd6R5M79GQsAYHXtJaBenOS3ztn+zGIfAMAV7cBPpFlVJ5KcWGz+blV94qCf82vP/ZbDeqaRq5N8YdlDrBhrcj5rcj5rcj5rcj5r8kyX1Xrs9uf2Hn++T9bkT13sjr0E1ONJXnLO9nWLfc/Q3fckuWcPz3NFqarT3X1s2XOsEmtyPmtyPmtyPmtyPmvyTNbjfPu1Jnt5Ce/XktxYVTdU1fOTvDbJ/XsdCABg1V3yEajufqqq/l6S/5TkqiRv6+5H9m0yAIAVtaf3QHX3Lyb5xX2a5ajwcub5rMn5rMn5rMn5rMn5rMkzWY/z7cuaVHfvx9cBADgyXMoFAGBIQB2SqvqBqnqkqr5aVcfO2f+qqnq4qj66+HjrMuc8TBdbk8V9b1xcIugTVfXdy5pxmarq5qp6f1V9uKpOV9Uty55p2arq71fVbyz+3PzYsudZFVX1hqrqqrp62bMsW1X9+OLPyK9X1Xur6oXLnmlZXG7tmarqJVX1vqr6+OJ7yOv28vUE1OH5WJK/muRXn7X/C0n+cnd/W5LjSf7tYQ+2RBdck8UlgV6b5KVJbk/yrxeXDjpqfizJj3b3zUn+6WL7yKqqV2b7agcv6+6XJvkXSx5pJVTVS5K8Osn/XvYsK+KBJH+mu/9skv+Z5I1LnmcpXG7tgp5K8obuvinJK5L88F7WREAdku5+tLvPO4lod3+ouz+72HwkyddV1QsOd7rluNiaZPuH5Du6+yvd/b+SPJbtSwcdNZ3kjy1u//Ekn32Oxx4FP5TkZHd/JUm6+8klz7Mq3prkR7L95+XI6+5f6u6nFpvvz/Y5Co8il1t7lu5+ors/uLj95SSPZg9XUBFQq+WvJfng0z8gjjCXCdr2+iQ/XlW/le2jLUfyX9Ln+JYkf6GqHqqq/1JV377sgZatqu5M8nh3f2TZs6yov53kPyx7iCXxffQ5VNVGkpcneehSv8aBX8rlKKmq/5zkT17grjd39307fO5Lk7wl24firxh7WZOj4LnWJ8ltSf5Bd7+7ql6T5N4k33WY8x22HdZjLcmLsn3o/duTvKuqvqmv8F8l3mFN3pQr7HvGbuzm+0pVvTnbL9m8/TBnY/VV1dcneXeS13f371zq1xFQ+6i7L+mHW1Vdl+S9Sf5md//m/k61XJe4Jru6TNCV4LnWp6r+TZKn3+T4c0l++lCGWqId1uOHkrxnEUwfqKqvZvuaVmcPa75luNiaVNW3JbkhyUeqKtn+e/LBqrqluz93iCMeup2+r1TV30ryvUluu9ID+zkcme+jE1X1vGzH09u7+z17+VpewluyxW+IbCXZ7O7/vux5VsT9SV5bVS+oqhuS3JjkA0ueaRk+m+QvLm7fmuSTS5xlFfz7JK9Mkqr6liTPz2V0kdT91t0f7e5v7O6N7t7I9ks0f+5Kj6edVNXt2X5P2Pd19/9d9jxL5HJrz1Lb/9K4N8mj3f0Te/56RzfOD1dV/ZUk/zLJepIvJflwd393Vf2TbL+35dwfjq8+Cm+QvdiaLO57c7bfv/BUtg+zHrn3MVTVdyb5qWwfKf5/Sf5udz+83KmWZ/FD4G1Jbk7ye0n+UXf/8nKnWh1VdSbJse4+slGZJFX1WJIXJPntxa73d/ffWeJIS1NVfynJT+YPLrf2z5c80lItvqf+1yQfTfLVxe43La6qMv96AgoAYMZLeAAAQwIKAGBIQAEADAkoAIAhAQUAMCSgAACGBBQAwJCAAgAY+v8yrajMccmJFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2UJbaUfJWap",
        "colab_type": "text"
      },
      "source": [
        "표를 보면 모든 layer들과 토큰 값들은 비슷한데, 대부분의 값들은 [-2,2] 값 사이에 존재함을 알 수 있다.  \n",
        "몇몇의 값들은 -10이하로 존재함을 볼 수 있다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXrx99AUJ_0_",
        "colab_type": "text"
      },
      "source": [
        "현재의 모델은 layer기준으로 만들어졌지만, 우리는 token으로 묶여야 하므로 차원수를 조정해줘야 한다.\n",
        "\n",
        "Embedding layer의 차원 정보를 변환해주기로 한다.  \n",
        "현재 차원:\n",
        "\n",
        "`[# layers, # batches, # tokens, # features]`\n",
        "\n",
        "바꾸고자 하는 차원:\n",
        "\n",
        "`[# tokens, # layers, # features]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F__jmE4IK6u1",
        "colab_type": "text"
      },
      "source": [
        "첫번째 차원을 보기로 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF_CytzLI55a",
        "colab_type": "code",
        "outputId": "1ac6aed2-a0eb-412c-faa6-b12b08f02f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Python tuple로 되어있고,\n",
        "print('      Type of hidden_states: ', type(hidden_states))\n",
        "\n",
        "# 각 layer당 torch tensor 개수를 보여준다.\n",
        "print('Tensor shape for each layer: ', hidden_states[0].size())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Type of hidden_states:  <class 'tuple'>\n",
            "Tensor shape for each layer:  torch.Size([1, 22, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFx-nXjzI8kC",
        "colab_type": "code",
        "outputId": "b30413a0-4784-4c7e-a754-ed92e3152160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# 모든 Embedding layer를 쌓아준다.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 1, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87tNYCbwI96Z",
        "colab_type": "code",
        "outputId": "74d15702-bc4b-4580-8fbc-e97588b9efb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# batch 정보를 제거해준다..\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB7vnR8XI_TM",
        "colab_type": "code",
        "outputId": "e4b4f6dd-1aa6-4a50-83eb-0ccdb076b914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# 0(layer 정보)과 1차원(token 정보)를 추가 조정해준다.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 13, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xjcMtX-IAio",
        "colab_type": "text"
      },
      "source": [
        "#### Word Vectors\n",
        "\n",
        "Word Vector를 두가지 방법으로 만들어보자.\n",
        "1. 4개의 레이어로 나눠서 만들어보기  \n",
        "\n",
        "각 vector당  `4x768=3072` 를 가지게 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5G_sfvFM-Ww",
        "colab_type": "code",
        "outputId": "23bd0b70-842b-4afe-bd3c-4c9c997c5f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# token_vecs_cat 정보를 토큰 vector 정보를 저장해준다. [22 x 3,072]\n",
        "token_vecs_cat = []\n",
        "\n",
        "# `token_embeddings`에는 총 [22 x 12 x 768] tensor가 존재한다.\n",
        "# `token`에는 [12 x 768] tensor가 있다.\n",
        "for token in token_embeddings:\n",
        "    #torch.cat로 4개의 layer들로 나누어준다.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixhXRC9sMbf5",
        "colab_type": "text"
      },
      "source": [
        "2. four layer 값들을 다 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erknNXR2NCZP",
        "colab_type": "code",
        "outputId": "1387408b-62fb-4c1c-ecd4-53b078fc35b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#token_vecs_sum 정보를 토큰 vector 정보를 저장해준다 [22 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings`에는 총 [22 x 12 x 768] tensor가 존재한다.\n",
        "# `token`에는 [12 x 768] tensor가 있다.\n",
        "for token in token_embeddings:\n",
        "    #위에는 4개로 나누지만, 여기서는 1개로 합친다.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBi_muVPIFYE",
        "colab_type": "text"
      },
      "source": [
        "#### Sentence Vectors\n",
        "\n",
        "하나 문장을 하나의 vector로 나타나기 위해, 여러 방식을 응용하는 전략을 가지고 있지만  \n",
        "간단한 방법은 각 token은 하나의 768 길이 벡터를 마지막 layer에 평균하는 것이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbfLHcWcNLmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `hidden_states`은 [13 x 1 x 22 x 768]의 크기를 가진다.\n",
        "\n",
        "# `token_vecs`은 [22 x 768]크기의 tensor를 가진다.\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# 22 token vector의 평균값\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abEedhy-NOdn",
        "colab_type": "code",
        "outputId": "075a2a88-7ae9-4d17-9a5e-d879bc500a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our final sentence embedding vector of shape: torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyE6GWKJNpjo",
        "colab_type": "text"
      },
      "source": [
        "#### 문맥적으로 독립적인 Vector 확정하기\n",
        "\n",
        "Vector들의 값들을 확정한다는 것은 각각의 단어들은 문맥적으로 독립적임을 말한다.  \n",
        "input 문장에 나온 \"bank\" 단어들의 예로 살펴보자.\n",
        "\n",
        "\"After stealing money from **the bank vault**, the **bank robber** was seen fishing on the Mississippi **river bank**.\"  \n",
        "여기서 bank vault와 bank rover는 동일한 의미를 가지고,  \n",
        "river bank와는 다른 의미를 가진 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wad1-8nlNWBw",
        "colab_type": "code",
        "outputId": "e8bf8435-0921-4aba-93f1-9ef83f11754d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "print('First 5 vector values for each instance of \"bank\".')\n",
        "print('')\n",
        "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
        "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
        "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 vector values for each instance of \"bank\".\n",
            "\n",
            "bank vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
            "bank robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
            "river bank    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olgHLvC6N392",
        "colab_type": "text"
      },
      "source": [
        "각각 단어들은 6, 10, 19에 있다.  \n",
        "이 결과를 보면, 위에 만든 word vector중 4개의 레이어들을 모두 합친 방식으로 보면,  \n",
        "tensor들이 각각 다른 값을 가진 것을 보아 문맥적으로 독립적인 값을 가진 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVHVFIxfOtgO",
        "colab_type": "text"
      },
      "source": [
        "tensor들의 값이 다른 것만으로는 제대로 알 수 없으므로, 확률을 이용해 더 정확한 비교를 해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl4_aV5JNYKZ",
        "colab_type": "code",
        "outputId": "a65e0de2-5cc7-4143-a828-b57fcd3ca2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# 단어 bank를 통해 코싸인 유사성을 비교해보자.\n",
        "# \"bank robber\" vs \"river bank\" (다른 의미).\n",
        "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
        "\n",
        "# in \"bank robber\" vs \"bank vault\" (같은 의미).\n",
        "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.94\n",
            "Vector similarity for *different* meanings:  0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FuCke4kPq-E",
        "colab_type": "text"
      },
      "source": [
        "다른 의미를 가지는 bank와는 유사성 69%를 가지고,\n",
        "같은 의미를 가지는 bank와는 유사성 94%를 확인해볼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sId9xrYQBSL",
        "colab_type": "text"
      },
      "source": [
        "# 끝내며..\n",
        "### 한국어 BERT [https://korquad.github.io/]  \n",
        "한국어에 적용하며 모델의 성능을 확인하는 KorQuAD 대회가 진행중(6월 19일까지)이다.  \n",
        "전체 데이터는 47,957 개의 Wikipedia article에 대해 102,960 개의 질의응답 쌍이다.  \n",
        "현재 1등의 EM, F1 값들을 확인해보면 73.87, 86.81으로 Human Performance를 훨씬 뛰어넘은 성능을 보여준다.\n",
        "\n",
        "\n",
        "### BERT의 파생 모델과 현재\n",
        "BERT 성능이 높음에 따라 BERT를 활용한 여러 모델들이 파생되었다.  \n",
        "\n",
        "\n",
        "\n",
        "<p align = \"center\">\n",
        "<img src=\"https://miro.medium.com/max/4484/1*HOo-D0IwSlBsoruw1J6Q-w.png\" width =600px align=\"center\"></p>\n",
        "\n",
        "딥러닝을 이용해 요구되는 모델의 크기가 급격히 커져, 다양한 문제점이 등장하고 있는 현실이다.\n",
        "- 모델이 커짐에 따른 메모리 사이즈 제한\n",
        "- 학습/추론 과정에 많은 시간 소요\n",
        "- 성능 저하\n",
        "- GPU 부족\n",
        "\n",
        "이에 따라 모델 압축(Model Compression) 연구 분야가 현재 주목을 받고 있는 실정이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2DRrc07QOVx",
        "colab_type": "text"
      },
      "source": [
        "# 참고문헌:\n",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding \n",
        "- [https://arxiv.org/pdf/1810.04805.pdf]  \n",
        "\n",
        "Google-Research BERT \n",
        "- [https://github.com/google-research/bert]\n",
        "- [https://github.com/huggingface]  \n",
        "\n",
        "BERT Word Embedding 코드 참조\n",
        "- [https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/]  \n",
        "- [https://github.com/soutsios/pos-tagger-bert/blob/master/pos_tagger_bert.ipynb]  "
      ]
    }
  ]
}